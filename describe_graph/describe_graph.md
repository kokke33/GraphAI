# :star:wikipedia.yaml

このグラフは、サム・バンクマン・フリードに対する裁判所の最終判決についての情報を取得し、処理するためのワークフローを示しています。以下に各ノードの役割を説明します。

1. **sourceノード**:
   - ユーザーからの情報を格納します。ここでは、サム・バンクマン・フリードの名前、トピック（裁判所の文）、およびクエリが含まれています。

2. **wikipediaノード**:
   - `wikipediaAgent`を使用して、Wikipediaからサム・バンクマン・フリードに関するデータを取得します。ノードが実行される前にコンソールにメッセージを表示します。

3. **chunksノード**:
   - 取得したWikipediaの記事をチャンクに分割します。これも、処理前にメッセージを表示します。

4. **embeddingsノード**:
   - 分割されたテキストチャンクの埋め込みを取得します。この処理の前にもメッセージが表示されます。

5. **topicEmbeddingノード**:
   - ユーザーが指定したトピックに対する埋め込みを取得します。

6. **similarityCheckノード**:
   - 埋め込みの類似性を確認します。具体的には、チャンクの埋め込み行列とトピックの埋め込みベクトルのドット積を計算します。

7. **sortedChunksノード**:
   - 類似性に基づいて、チャンクをソートします。

8. **referenceTextノード**:
   - ソートされたチャンクから参照テキストを生成します。ここでは、最大5000トークンまで取得します。

9. **promptノード**:
   - ユーザーのクエリと参照テキストを組み合わせ、最終的なプロンプトを作成します。

10. **RagQueryノード**:
    - RAG（Retrieval-Augmented Generation）クエリを実行し、得られたプロンプトを使用してOpenAIエージェントに問い合わせます。

11. **OneShotQueryノード**:
    - ユーザーのクエリを直接OpenAIエージェントに送信します。

12. **RagResultノード**:
    - RAGクエリの結果をコピーし、最終的な結果としてマークします。

13. **OneShotResultノード**:
    - One Shotクエリの結果をコピーし、こちらも最終的な結果としてマークします。

このグラフは、サム・バンクマン・フリードに関する裁判所の判決を効率的に取得し、ユーザーの質問に対する応答を生成するための一連のプロセスを示しています。

# :star:research.yaml
このJSONデータは、特定のトピックに関する情報を取得し、言語を検出し、必要に応じて翻訳を行うエージェントワークフローを示しています。以下に各部分の説明を行います。

## 構造の概要

1. **topicノード**:
   - ユーザーに研究したいトピックの入力を求めるエージェント（`textInputAgent`）です。

2. **detectorノード**:
   - 入力されたトピックの言語を検出するためのネストされたエージェントです。
   - `openAIAgent`を使用して、入力されたトピックの言語を識別し、英語に翻訳します。
   - 翻訳結果は`translated`関数を通じて報告されます。

3. **wikipediaノード**:
   - 言語検出の結果に基づき、Wikipediaからトピックに関する情報を取得します。
   - `wikipediaAgent`を使用して、トピックに関連する内容を取得し、その後、要約するために再び`openAIAgent`を用います。

4. **translateノード**:
   - Wikipediaから取得した内容を翻訳するためのネストされたエージェントです。
   - 言語情報に基づき、英語である場合はそのまま内容を返し、他の言語の場合は翻訳を実行します。
   - 翻訳には再び`openAIAgent`が使用されます。

## フローの詳細

- ユーザーがトピックを入力すると、そのトピックが`topic`ノードで受け取られます。
- `detector`ノードは、そのトピックの言語を識別し、必要に応じて英語に翻訳します。
- 次に、`wikipedia`ノードがそのトピックに関する情報をWikipediaから取得し、要約します。
- 最後に、`translate`ノードが要約内容を翻訳し、結果を返します。

このフローは、ユーザーからの入力を基にして、言語の検出、情報の取得、要約、翻訳を行う一連のプロセスを非同期に実行します。各ノードは、前のノードからの出力を入力として使用し、全体のデータフローを形成しています。


# :star:checkIdea
このGraphAIのコードは、ユーザーとの相談を進行するためのフローを定義しています。以下に、その主要な構成要素と流れについて説明します。

## 1. **バージョンとループ**:
   - バージョンは0.5で、無限ループを設定しています。これは、ユーザーが「bye」と入力するまで、フローが続くことを意味します。

## 2. **ノードの説明**:
   - **continue**: ループが続くかどうかを示すブール値を持ち、`checkInput`からの更新を受けます。
   - **userInput**: ユーザーに相談内容を入力させるためのエージェントです。
   - **checkInput**: ユーザーの入力が「bye」でないかを確認します。
   - **summary**: 会話の要約を格納するための空の配列です。
   - **accumulationSummary**: 会話の要約を生成するテンプレートエージェントです。
   - **reducer**: 新しい要約を`summary`配列に追加するためのエージェントです。
   - **suggestIdea**: ユーザーの相談内容に対するアイデアを生成します。
   - **suggestIdea_LLM**: OpenAIのエージェントを使用して、アイデアを生成します。
   - **evaluationIdeas**: 生成したアイデアを評価するためのテンプレートです。
   - **evaluationIdeas_LLM**: アイデアの評価を行うOpenAIのエージェントです。
   - **selectTop3**: 提案されたアイデアから最も適切な3つを選定します。
   - **selectTop3_LLM**: 選定したアイデアの評価を行うOpenAIのエージェントです。
   - **output**: 最終的な結果を整形して出力します。
   - **nextQA**: 次の質問を生成するためのテンプレートです。
   - **nextQA_LLM**: 次の質問を生成するOpenAIのエージェントです。
   - **summaryChat**: ユーザーの相談内容と対応策をまとめるためのテンプレートです。
   - **summaryChat_LLM**: まとめた内容を生成するOpenAIのエージェントです。
   - **matome**: 会話の流れを整形して出力します。

## 3. **フローの流れ**:
   - ユーザーが相談内容を入力すると、それが`userInput`ノードで処理されます。
   - 入力が「bye」でない場合、アイデアの提案が行われ、生成されたアイデアは評価されます。
   - 評価されたアイデアの中からトップ3が選ばれ、それに基づいて次の質問が生成されます。
   - 最終的に、すべての結果が出力され、会話の流れがまとめられます。

このフローによって、ユーザーとのインタラクションがスムーズに進み、相談内容に基づいた具体的なアイデアや質問が生成されます。